\section{proof of the main theorem}

After having proved all the basic geometric facts, we will turn our attention to finally prove the main theorem (for $\var{char}(k) \neq 2$).
\begin{theorem}
Let $k$ be an algebraically closed field, $\var{char } k \neq 2$ and let $S = \V(f) \subset \proj^3_k$ be a non-singular cubic surface, $f\in k[x,y,z,t]$.
Then $S$ contains precisely 27 lines.
\end{theorem}
We will follow the proof given by Miles Reid (\cite[ยง7]{reid1988undergraduate}).

\subsection{existence of a line}

We take an arbitrary point $P_0 \in S$ and consider its tangent plane $T_{P_0}(S) = \V(f^{(1)}(P_0))$.
Of course, no plane lies in $S$ completely, as this would imply the existence of singular points by lemma \ref{lemmaSingularIntersect}.
By restricting the equation of $S$ to the tangent plane we obtain a 3-form $f' = f - f^{(1)}(P_0)g$, $g$ being some quadratic form.
If we're lucky $f'$ is reducible and hence a product of a linear and a quadratic form meaning that the intersection $T_{P_0}(S) \cap \V(f^{(1)}(R)) \simeq \V(f') \subset \proj^2_k$ is a union of a line and a conic (possibly a degenerate one).
So in this case $S$ contains a line.
Let's proceed assuming that we are unlucky and say $\V(f') \subset \proj^2_k$ is an irreducible cubic curve.
To simplify things, move tangent plane at $P_0$ to the plane $\V(t)$ and simultaneously move the point $P_0$ to $[0:0:1:0]$ by corollary \ref{corollaryTransformPlaneWithPointOnIt}.
That this transforms the surface in a compatible manner with the tangent plane has been proven in proposition \ref{propositionTangentTransform}.
Eliminating the variable $t = 0$, $f(x,y,z,0)$ defines a cubic curve.
By lemma \ref{lemmaIntersectionWithTangent} it is singular at $[0:0:1:0]$ and we know it is projectively equivalent to either $\V(x^2z - y^3)$ or $\V(x^3 + y^3 - xyz)$ by propositions \ref{propositionClassificationOfSingularCubics}, \ref{propositionNormalformCuspidal} and \ref{propositionNormalformNodal2}.
This however is only true if the characteristic of $k$ is not $3$, so we have to hope that the nodal case occurs somewhere.
We can lift this automorphism of the hyperplane $\V(t)$ to an automorphism of the whole space via proposition \ref{propositionLiftingAutomorphisms}.

\subsubsection{the cuspidal case}
Let's focus on the case where our cubic curve is cuspidal. By previous transformations $f = x^2z - y^3 + tg$, $g$ being a quadratic form.
The partial derivatives of $f$ are
\begin{align}
   \del_x f =& 2xz + t\del_x g
\\ \del_y f =& -3y^2 + t\del_y g
\\ \del_z f =& x^2 + t\del_z g
\\ \del_t f =& g + t\del_t g
\end{align}
and $f^{(1)}(0,0,1,0) = g(0,0,1,0)t$.
Due to the non-singularity of $f$ the form $g$ has a $z^2$ term with some coefficient $\tau := g(0,0,1,0) \in k^\times$.

We've set ourselves up to employ the next technique of finding a line on the surface.
Let $P= (1,\alpha,\alpha^3,0)$ represent be an indeterminate point on the surface,
and let $Q = (0,y,z,t)$ represent a indeterminate point on the hyperplane $\V(x)$.
Surely $P$ and $Q$ cannot coincide for any choice of $\alpha,y,z,t$.
We wish to show that for some $\alpha,y,z,t$ the line $\overline{P,Q}$ is contained in the cubic surface.
As we have seen in the section on linear subsets, it suffices to show $f(\lambda P + \mu Q) = 0 \in k[\lambda,\mu]$.
Combining this with the poor student's Taylor expansion (corollary \ref{corollaryTaylorForQuadricAndCubic}) we obtain
$f(\lambda P + \mu Q)
= \underset{=\lambda^3 f(P) = 0}{\underbrace{f(\lambda P)}}
+ f^{(1)}(\lambda P;\mu Q)
+ f^{(1)}(\mu Q;\lambda P)
+ f(\mu Q)
= \lambda^2\mu f^{(1)}(P;Q)
+ \lambda\mu^2 f^{(1)}(Q;P)
+ \mu^3 f(Q)$.
So by equating coefficients the condition for $\overline{P,Q}$ to lie on the cubic surface reduces to
\begin{align}
A :=  f^{(1)}(P;Q) = -3\alpha^2 y + z + tg(1,\alpha,\alpha^3,0) =& 0 \\
B :=  f^{(1)}(Q;P) = -3\alpha y^2 + tg^{(1)}(0,y,z,t;1,\alpha,\alpha^3,0) =& 0 \\
C :=  f(Q)         = -y^3 + tg(0,y,z,t) =& 0
\end{align}

Consider now $A,B,C \in k(\alpha)[y,z,t]$ as homogeneous 1-,2- and 3-form respectively over the field $k(\alpha)$.
$A,B,C$ have a common zero\footnote{note that we look for non-trivial solutions for $x,y,z$, otherwise $Q$ does not define a point in projective space!} iff $\emptyset \neq \V(A,B,C) = \V(A) \cap \V(B,C)$.
$\V(A)$ is a hyperplane, so we can eliminate some variable. Here it is $z = Z := 3\alpha^2 y - t\underset{=: \tau a^{(6)}}{\underbrace{g(1,\alpha,\alpha^3,0)}}$.
So the existence of a solution amounts to $\emptyset \neq \V(B',C')$ where we define $B' = B(y,Z,t), C' := C(y,Z,t)$.
We may write out $B',C'$ as
\begin{align}
B' = -3\alpha y^2 + tg^{(1)}(0,y,3\alpha^2y - \tau a^{(6)}t,t;1,\alpha,\alpha^3,0) =& b_0y^2 + b_1yt + b_2 t^2 \\
C' = -y^3 + tg(0,y,3\alpha^2y-\tau a^{(6)}t,t) =& c_0y^3 + c_1y^2t + c_2 yt^2 + c_3t^3
\end{align}
for some coefficients $b_0,..b_2,c_0,..c_3 \in k(\alpha)$ to be determined.

The condition for the forms $B'$ and $C'$ to have a (non-trivial) common zero is now a polynomial relation of their coefficients $b_i,c_i$, meaning that there exists a polynomial $R$, called the resultant polynomial, in the coefficients of $B',C'$ which vanishes iff $B',C'$ have a common zero.
This polynomial can be given by the determinant of a so-called Sylvester matrix
\begin{equation}
R =
\det\begin{pmatrix}
b_0 & b_1 & b_2 & 0 & 0 \\
0 & b_0 & b_1 & b_2 & 0 \\
0 & 0 & b_0 & b_1 & b_2 \\
c_0 & c_1 & c_2 & c_3 & 0 \\
0 & c_0 & c_1 & c_2 & c_3 \\
\end{pmatrix}
\end{equation}
You can find a proof in \cite[theorem 4.2.3]{brieskorn2012plane}, although it is not hard to find an elementary proof for this particular case.
\begin{proof}
The matrix represents a linear automorphism on the vector space of 4-forms mapping $x^4,x^3y,x^2y^2,xy^3,y^4$ to $x^2B',xyB',y^2B',xC',yC'$.
Now if $B',C'$ have a common zero $(x_0,y_0) \neq (0,0)$ so do $x^2B',xyB',y^2B',xC',yC'$ but of course the monomials $x^4,x^3y,x^2y^2,xy^3,y^4$ don't vanish simultaneously on $(x_0,y_0)$. This shows that the matrix is not invertible.
Conversely if the matrix is singular, then there exist some quadratic form $q$ and a cubic form $c$, not both 0, such that $cB' + qC' = 0 \Leftrightarrow cB' = -qC'$ (we can assume that $q,c$ are both non-zero, otherwise one of $B',C'$ is zero already).
But $k[x,y]$ is a unique factorisation domain and lemma \ref{lemmaFundamentalTheorem} gives us for both sides of the equation the decomposition into \emph{linear factors}, so by the pigeon hole principle, $B'$ and $C'$ must have some factor in common.
\end{proof}

We continue with inspecting the coefficients themselves.
Note that $g^{(1)}(X,X')$ is linear in each set $X$ or $X'$ of variables, hence bilinear.
We found out previously that $g(x,y,z,t)$ has a $z^2$ term, so $a^{(6)} = g(P) = \tau\alpha^6 + (\text{terms of smaller degree in } \alpha)$.
Putting this all together we can compute the coefficients $b_i$:
\begin{align}
b_0 =& -3\alpha \\
b_1 = g^{(1)}(1,\alpha,\alpha^3,0;0,1,3\alpha^2,0) =& 6\tau\alpha^5 + ... \\
b_2 = g^{(1)}(1,\alpha,\alpha^3,0;0,0,-\tau a^{(6)},1) =& -2\tau^2\alpha^9 + ...
\end{align}
And similarly for the $c_i$, we have $g(0,y,3\alpha^2y-\tau a^{(6)}t,t) = g(y(0,1,3\alpha^2,0)+t(0,0,-\tau a^{(6)},1))$ for which we can perform the poor student's Taylor expansion. This yields
\begin{align}
c_0 =& -1\\
c_1 = g(0,1,3\alpha^2,0) =& 9\tau\alpha^4 + ... \\
c_2 = g^{(1)}(0,1,3\alpha^2,0;0,0,-\tau a^{(6)},1) =& -6\tau^2\alpha^8 + ... \\
c_3 = g(0,0,-\tau a^{(6)},1) =& \tau^3\alpha^{12} + ...
\end{align}

Note that all coefficients lie in $k[\alpha]$.
We now to calculate the resultant polynomial and only regard the leading terms of the coefficients.
We will see that the determinant does not vanish, so this gives the leading term of the resultant.
Indeed, by manual evaluation (a tedious process of multiplying/dividing rows or columns of the matrix by powers of $\alpha$) of the determinant, we are able to obtain $\tau^6\alpha^{27} $ as leading term.
We've proven:
\begin{proposition}
Suppose $k$ has characteristic neither 2 nor 3.
If $T_{P_0}(S) \cap S$ is a cuspidal cubic curve, then there exists a polynomial $R \in k[\alpha]$ of degree 27, such that there exists a line on $S$ through $P(\alpha_0) = (1,\alpha_0,\alpha_0^3,0)$ iff $\alpha_0 \in k$ is a root of $R$.
\end{proposition}

\subsubsection{the nodal case}
\begin{todo}
\item need to set up everything again blabla
\end{todo}
By leveraging the power of the modern analytical engine -- by which I mean a computer algebra system like Sage \cite{sagemath2014} -- we can perform all these calculations easily, so let's not bother ourselves with lengthy calculations anymore.
The Sage script in listing \ref{listingCuspidal} computes the resultant with the same result as we have done manually so far.
A second Sage script (listing \ref{listingNodal}) gives us the following results for the nodal case:
We obtain a resultant $R' \in k(\alpha)$, such that $R := \alpha^{12}R' \in k[\alpha]$ is a polynomial in $\alpha$ with leading term $\tau'^6\alpha^{27}$ and constant term $\tau'^6$, $\tau'$ being a unit (in fact, $\tau$ is the coefficient of the $z^2$ term of the quadratic form $g$ in $f = x^3 + y^3 - xyz + tg'$, which just like $\tau$ is non-zero due to the non-singularity of the cubic surface).
This verifies:
\begin{proposition}
Suppose $k$ has characteristic not 2.
If $T_{P_0}(S) \cap S$ is a nodal cubic curve, then there exists a polynomial $R \in k[\alpha]$ of degree 27 not vanishing in 0, such that there exists a line on $S$ through $P(\alpha_0) = (\alpha_0,\alpha_0^2,1+\alpha_0^3,0)$ iff $\alpha_0 \in k$ is a root of $R$.
\end{proposition}

\subsubsection{sufficiency of the nodal case}

\subsection{finding the other lines}
\subsection{the configuration of the lines}



\begin{todo}
\item condition for a plane to generate lines
\end{todo}

Planes through the line $L=\V(x,t)$ are parametrised by $\proj^1_k$. Namely, their equations are given by $\lambda x + \mu t = 0, [\lambda:\mu] \in \proj^1_k$.
We can give a condition for a plane to intersect the cubic surface in three lines.
\begin{lemma}
View $f$ as a polynomial over $k[z,t]$ to get a decomposition as sum $f = Ax^2 + Bxy + Cy^2 + Dx + Ey F$, where $A,B,C,D,E,F \in k[z,t]$.
Let $[\lambda:\mu] \in \proj^1_k$.
The plane $\V(\lambda x + \mu t)$ intersects the cubic surface in three lines iff
% $4A(\lambda,\mu)C(\lambda,\mu)F(\lambda,\mu) + B(\lambda,\mu)D(\lambda,\mu)E(\lambda,\mu) - A(\lambda,\mu)E(\lambda,\mu)^2 - B(\lambda,\mu)^2F(\lambda,\mu) - C(\lambda,\mu)D(\lambda,\mu)^2 = 0$
$\Delta(\lambda,\mu) = 0$ where $\Delta = 4ACF + BDE - AE^2 - CD^2 - B^2F$ is a quintic form.
\end{lemma}

\begin{proof}
That $\Delta$ is a quintic form goes without saying.
We assume $\lambda \neq 0$ (the other case goes analogously).
In that case we can restrict $f$ to the plane $\V(\lambda z + \mu t)$ by eliminating $t = \frac\mu\lambda z$:
Notice that $A,B,C$ are linear forms, $D,E$ are quadratic forms and $F$ is a cubic form.
We eliminate $t$ from these forms and get
\begin{align}
A(z,t) =& A(z,\frac\mu\lambda z) = z\lambda^{-1} A(\lambda,\mu) \qquad \text{(and similarly for $B,C$)} \\
D(z,t) =& D(z,\frac\mu\lambda z) = z^2\lambda^{-2} D(\lambda,\mu) \qquad \text{(and similarly for $E$)} \\
F(z,t) =& F(z,\frac\mu\lambda z) = z^3\lambda^{-3} F(\lambda,\mu)
\end{align}

Hence $f$ restricts to $zq$ where $q \in k[x,y,z]$ is a quadratic form
\begin{equation}
q =
\lambda^{-1} A(\lambda,\mu) x^2
+\lambda^{-1} B(\lambda,\mu) xy
+\lambda^{-1} C(\lambda,\mu) y^2
+\lambda^{-2} D(\lambda,\mu) xz
+\lambda^{-2} E(\lambda,\mu) yz
+\lambda^{-3} F(\lambda,\mu) z^2
\end{equation}

In corollary \ref{corollarySingularConic} we found out that a quadratic form like $q$ factors into two linear forms iff a certain polynomial in the coefficients of $q$ vanishes.
By writing this condition out, one obtains $\lambda^{-5} \Delta(\lambda,\mu) = 0$ and multiplying by $\lambda^5$ we finally get as necessary and suffient condition for $q$ to factor into linear forms
\begin{equation}
\Delta(\lambda,\mu) = 0
\end{equation}
as desired.
\end{proof}

Being a quintic form, $\Delta$ has at most five zeroes on $\proj^1_k$, so the number of planes through $L$ which intersect the surface $S$ in three lines is bounded by five.
We will show that there are precisely five distinct such planes, but before that let's have a look on how the non-singularity of $S$ affects the possible configuration of lines.


% TODO begin

% TODO end 


