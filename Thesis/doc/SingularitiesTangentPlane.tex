\subsection{Singularities and the tangent space}

In this section we want to study the local properties of a projective variety.
A particularly simple tool is the tangent space.
The analytical idea behind it is to approximate, say, a surface near a point by a plane as close as possible.
That's what a FrechÃ©t differential does for, say,  the graph of some differentialble function $\reals^2 \to \reals$.
In the analytical world such a plane is defined via partial derivatives, which can be emulated for polynomials in a purely algebraic way.

\subsubsection{Partial derivatives}
\begin{definition}
Let $D : k[x_0,..x_n] \to k[x_0,..x_n]$ be a \emph{derivation} over $k$, i.e. a homomorphism of $k$-modules which satisfies the Leibniz rule $D(xy) = xDy+yDx$ for $x,y \in k[x_0,..x_n]$. Furthermore let $D(h) \in k$ for every linear form $h$. We call such a derivation a \emph{partial derivative}.
\end{definition}

\begin{example}
The standard example for partial derivatives are of course the partial derivates with respect to one of the variables $x_i$, defined as $\del_{x_i}(x_j) = \delta_{i,j} := \begin{cases} 1, & \text{ for } i = j \\ 0, & \text {otherwise.} \end{cases}$
\end{example}

\begin{example} \label{exampleAlternativePartialDerivatives}
For any basis $\{ h_i\}_{i=0}^n$ of the vector space of linear forms $\bigoplus_{i=0}^n kx_i \subset k[x_0,..x_n]$ we obtain a family of partial derivatives $\{ \del_{h_i} \}_{i=0}^n$ for which $\del_{h_i}(h_j) = \delta_{i,j}$ holds. The construction goes as follows: Let $M = (a_{i,j})  \in k^{(n+1)\times(n+1)}$ be the base change matrix and $M^{-1} = (\widetilde a_{i,j})$ be its inverse.
This just means $h_i = \sum_{j=0}^n a_{i,j} x_j$ and hence $\del_{x_k}(h_i) = a_{i,k}$.
From $\delta_{i,j} = \sum_{k=0}^n a_{i,k}\widetilde a_{k,j}
= \sum_{k=0}^n \del_{x_k}(h_i) \widetilde a_{k,j}$ it is obvious that we need to define

\begin{equation}
\del_{h_j} = \sum_{k=0}^n \widetilde a_{k,j} \del_{x_k}
\end{equation}

Another way to write this would be
\begin{equation}
\begin{pmatrix} \del_{h_0} \\ \vdots \\ \del_{h_n} \end{pmatrix}
= M^{-T}
\begin{pmatrix} \del_{x_0} \\ \vdots \\ \del_{x_n} \end{pmatrix}
\end{equation}
\end{example}

A useful fact, that allows us to recover a homogeneous polynomial by its partial derivatives is

\begin{proposition}[Euler's formula]
For any $f \in k[x_0,..x_n]$ homogeneous of degree $d$ we have the equality
\[ df = \sum_{i=0}^n \del_{x_i}(f)x_i \]
\end{proposition}
\begin{proof}
By linearity we only need to prove the monomial case $f = \prod_{i=0}^n x_i^{a_i}$, $a_i$ being integers such that $\sum_{i=0}^n a_i = d$.
\begin{equation}
\sum_{i=0}^n \del_{x_i}(f)x_i
= \sum_{i=0}^n \begin{Bmatrix} \left(\prod_{j\neq i} x_j^{a_j}\right) a_i x_i^{a_i-1} x_i, & \text{ for } a_i > 0
\\ 0, &\text{ for } a_i = 0 \end{Bmatrix}
= \sum_{i=0}^n a_i f = df
\end{equation}
\end{proof}

\begin{corollary}
$\V(\del_{x_0}(f),..\del_{x_n}(f), df) = \V(\del_{x_0}(f),..\del_{x_n}(f))$
\end{corollary}

\begin{lemma} \label{lemmaPartialDerivativesCommute}
Let $\del_1,\del_2$ be partial derivatives, then $\del_1.\del_2 = \del_2.\del_1$.
\end{lemma}
\begin{proof}
We only need to prove this for monomials, and we'll perform an induction on the degree.
If $f$ is a monomial of degree less than 2, then $\del_1(\del_2(f)) = 0 = \del_2(\del_1(f))$. 
Now suppose $f = x_if'$ and $\del_1(\del_2(f')) = \del_2(\del_1(f'))$.

\begin{equation}
\del_1.\del_2(x_if') = \del_1(x_i\del_2(f') + f'\del_2(x_i)) = 
\del_1(x_i)\del_2(f') + \del_1(f')\del_2(x_i) + x_i\del_1(\del_2(f')) + \underset{=0}{\underbrace{f'\del_1(\del_2(x_i))}}
\end{equation}
The last term is symmetric in $\del_1,\del_2$ (by assumption).
\end{proof}

As a final fact about partial derivatives, I want to state the chain rule.
\begin{lemma}[chain rule]
Let $f \in k[x_0,..x_n]$ be a homogeneous polynomial and $F_0,..F_n \in k[x_0,..x_m]$ polynomials of same degree. They define a morphism $F : \proj^m_k \to \proj^n_k$. We define the composition $f.F := f(F_0,..F_n)$. The following equality holds for $0 \leq i \leq n$:
\begin{equation}
\del_{x_i} (f.F) = \sum_{j=0}^n ((\del_{x_j}f).F) \cdot \del_{x_i}(F_j)
\end{equation}
\end{lemma}
One can easily verify this for $f$ being a power of one variable, then for $f$ being a monomial and finally for a general polynomial $f$.

The following formula will come in handy for some calculations.
It will allow us to understand terms of the form $f(P+Q)$ for a homogeneous polynomial $f$ and points $P,Q$ better.
The idea is kind of related to Taylor's formula, which allows one to understand terms of the form $f(x + \delta x)$.
\begin{proposition}[poor student's Taylor expansion] \label{propositionTaylor}
Let $f \in k[x_0,..x_n]$ be a homogeneous polynomial of degree $d$.
There exists a unique decomposition of $f(X+X') := f(x_0+x'_0,..x_n+x'_n) \in k[x_0,..x_n,x'_0,..x'_n], \quad X := (x_0,..x_n), X' := (x'_0,..x'_n)$ into the sum
\begin{equation}
f = \sum_{i=0}^d f^{(i)}
\end{equation}
where $f^{(i)}$ is homogeneous of degree $i$ in the variables $x'_0,..x'_n$ and homogeneous of degree $d-i$ in the variables $x_0,..x_n$.

The $f^{(i)}$ are symmetric in the sense that $f^{(i)}(X;X') = f^{(d-i)}(X';X)$ for $1 \leq i \leq d$.
For $i = 0,1$ we have the explicit formulas
\begin{align}
f^{(0)}(X;X') =& f(X)  \label{eqPolar1}
\\ f^{(1)}(X;X') =& \sum_{i=0}^n (\del_{x_i}f)(X) x'_i \label{eqPolar2}
\end{align}
\end{proposition}
\begin{proof}
The polynomial $f(X+X')$ is homogeneous in $k[x_0,..x_n;x'_0,..x'_n]$ with the standard grading.
The existence of the decomposition and its uniqueness follow immediately by considering $f(X+X')$ as element of, say, $k(x_0,..x_n)[x'_0,..x'_n]$.
The symmetry property comes by applying the decomposition to $f(X'+X)$ (just interchange $X$ and $X'$), but obviously $f(X'+X) = f(X+X')$.
By comparing degrees in the variables $x_0,..x_n$ we then get $f^{(i)}(X;X') = f^{(d-i)}(X';X)$ as desired.
Equation \ref{eqPolar1} holds, as $f(X+0) = \sum_{i=0}^d f^{(i)}(X;0,..) = f^{(0)}(X;0)$.
We can see that equation \ref{eqPolar2} holds too:
We can isolate the degree 1 terms in $x'_0,..x'_n$ by taking the partial derivatives and evaluating at $X'=0$.
This forgets the terms of degree 0 and degree $\geq 2$.
Then we can recover $f^{(1)}$ by Euler's formula.
Hence $f^{(1)}(X;X') = \sum_{i=0}^n (\del_{x'_i}f(X+X'))(X;0,..) x'_i
\overset{\text{chain rule}}= \sum_{i=0}^n \left( \sum_{j=0} \del_{x'_j}f(X+X') \del_{x'_i}(x_j + x'_j) \right)(X;0,..)x'_i = \sum_{i=0}^n (\del_{x'_i} f)(X) x'_i$.
\end{proof}

\begin{remark}
The polynomial $f^{(1)}$ is also called the \emph{polar form} of $f$ in \cite[p. 104]{reid1988undergraduate}.
\end{remark}

\begin{corollary} \label{corollaryTaylorForQuadricAndCubic}
Let $g$ be a quadratic form and $f$ a cubic form. Then
\begin{align}
g(X+X') =& g(X) + g^{(1)}(X;X') + g(X')
\\ f(X+X') =& f(X) + f^{(1)}(X;X') + f^{(1)}(X';X) + f(X')
\end{align}
In particular, for $X=X'$: $4g(x) = g(X+X) = g(X) + g^{(1)}(X;X) + g(X)$ so $2g(X) = g^{(1)}(X;X)$ or conversely $g^{(1)}(X;X') = g(X+X') - g(X) - g(X')$, so we may view $g^{(1)}(X;X')$ as symmetric bilinear form.
\end{corollary}

\begin{example}
Let's say $f = x^3 + y^3 - xyz \in k[x,y,z]$ and we want to understand $f(x+d_x,y+d_y,z+d_z) \in k[x,y,z,t,d_x,d_y,d_z,d_t]$.
This yields
\begin{align*}
f(x+d_x,y+d_y,z+d_z)
  =& (x^3 + y^3 - xyz)
\\+& (3x^3d_x + 3y^2d_y + yzd_x + xzd_y + xyd_z)
\\+& (3d_x^3x + 3d_y^2y + d_yd_zx + d_xd_zy+d_xd_yz)
\\+& (d_x^3 + d_y^3 - d_xd_yd_z)
\end{align*}
\end{example}


\subsubsection{The tangent space}

\begin{definition} \label{definitionTangentSpace}
Let $\V(I)$ be a projective variety in $\proj^n_k$, $I \subset k[x_0,..x_n]$ a homogeneous ideal and $P\in \V(I)$ a point on that variety.
If $I$ is generated by a single homogeneous polynomial $f$, then we define $T_P(\V(f))$ to be the variety $\V(f^{(1)}(P))$ where $f^{(1)}(P) := f^{(1)}(P;x_0,..x_n)$.
If $I$ is generated by homogeneous polynomials $f_0,..f_r$, then we define $T_P(\V(I)) = \bigcap_{i=0}^r T_P(f_i)$.
We will see in a second that the choice of generators does not matter.
\end{definition}

\begin{example} \label{exampleTangentPlaneOfLinearSubsets}
Let's consider some trivial examples first.
The tangent space of a hyperplane $\V(h)$ at any point $P$ is the hyperplane itself, by Euler's formula:
\begin{equation}
h = \sum_{i=0}^n \underset{\in k}{\underbrace{(\del_{x_i}h)}}x_i = \sum_{i=0}^n (\del_{x_i}h)(P) x_i = h^{(1)}(P)
\end{equation}
The same holds for \emph{linear subspaces}, which are just intersections of hyperplanes (for instance lines or points).
\end{example}

\begin{example}
Suppose $I \subset J \subset k[x_0,..x_n]$ are homogeneous ideals, $P \in \V(I)$.
One can see that $T_P(I) \subset T_P(J)$ as follows: Let $f_0,..f_r$ be generators of $I$ and $g_0,..g_s$ be generators of $J$.
Because $I$ lies in $J$, we can write each $f_i$ as sums of products of the $g_j$.
By definition $T_P(\V(J)) = \bigcap_{j=0}^s \V(g_j^{(1)})$.
Consider now the set $K = \mkset{ f \in k[x_0,..x_n] }{f^{(1)}(P) \text{ vanishes on }T_P(\V(J))}$.
By the identities $(f+g)^{(1)}(P) = f^{(1)}(P) + g^{(1)}(P)$ and $(fg)^{(1)}(P) = f(P)g^{(1)}(P) + g(P)f^{(1)}(P)$ it can be easily checked that $K$ is an ideal.
We defined it to contain the $g_j$, so it also contains the $f_i$.
This shows that $\V(J) \subset \V(I)$ implies $T_P(\V(J)) \subset T_P(\V(I))$ and hence by choosing $I=J$ it also shows that the choice of generators in Definition \ref{definitionTangentSpace} did indeed not matter.
\end{example}

\begin{example}
Consider the family of cubic curves in $\proj^2_k$ given by $y^2z - x^3 - axz^2 \in k[x,y,z]$, $a \in k$ and let $P = [0:0:1] \in \V(y^2z - x^3 - axz^2)$.
The equation of the tangent space is $ax$, hence the tangent space is the line $x = 0$ unless $a = 0$ in which case the tangent space is the whole $\proj^2_k$.
Points for which the tangent space `degenerates' are rather special and hence deserve a name.
\end{example}


\begin{definition}
A \emph{singular} point of a hypersurface $\V(f) \subset \proj^n_k$ is a point in $\V(f,\del_{x_0}f,..\del_{x_n}f)$.
In other words, a point $P$ is singular iff $T_P(\V(f)) = \proj^n_k$.
\end{definition}

Singular points are worth studying because they behave well under automorphisms of projective space.

\begin{proposition} \label{propositionTangentTransform}
Let $\phi : \proj^n_k \to \proj^n_k$ be a projective transformation.
Then $\phi(T_P(\V(f))) = T_{\phi(P)}(\phi(\V(f)))$.
\end{proposition}

This is actually a corollary of a more general fact about \emph{linear embeddings}.

\begin{proposition} \label{corollaryTangentPullback}
Let $V\subset \proj^N_k$ be a subvariety, $\iota = (\iota_0,..\iota_N): \proj^n_k \hookr \proj^N_k$ a linear embedding and $\iota^{-1}(V) \subset \proj^n_k$. This situation is best described by a commutative diagram:
\begin{equation}
\begin{xy}
(0,20)*+{\proj^n_k}="pn";
(30,20)*+{\proj^N_k}="pN";
(0,0)*+{\iota^{-1}(V)}="iv";
(30,0)*+{V}="v";
{\ar@{^{(}->} "pn";"pN"}?*!/_2mm/{\iota};
{\ar@{^{(}->} "iv";"v"}?*!/_2mm/{\iota|_{\iota^{-1}(V)}};
{\ar@{_{(}->} "iv";"pn"};
{\ar@{_{(}->} "v";"pN"};
\end{xy}
\end{equation}
Then $T_{\iota^{-1}(P)}(\iota^{-1}(V)) = \iota^{-1}(T_P(V)) $ holds for $P$ in the image of $\iota$.
\end{proposition}
\begin{proof}
Because intersections are well-behaved under preimages, we assume $V$ to be a hypersurface $\V(f)$.
We have the equalities $\iota^{-1}(T_P(\V(f))) = \iota^{-1}(\V(f^{(1)}(P))) = \V(f^{(1)}(P).\iota)$ and $T_{\iota^{-1}(P)}(\iota^{-1}(\V(f))) = T_{\iota^{-1}(P)}(\V(f.\iota)) = \V((f.\iota)^{(1)}(\iota^{-1}(P)))$, therefore it's enough to show
\begin{equation}
(f.\iota)^{(1)}(\iota^{-1}(P))
=
f^{(1)}(P).\iota
\end{equation}

The calculation goes as follows
\begin{align}
(f.\iota)^{(1)}(\iota^{-1}(P))
  \defeq& \sum_{i=0}^n \del_{x_i}(f.\iota)(\iota^{-1}(P))x_i
\\\overset{\text{chain rule}}=& \sum_{i=0}^n \left(\sum_{j=0}^n ((\del_{x_j}f).\iota) \cdot \underset{\in k}{\underbrace{\del_{x_i}(\iota_j)}}\right)(\iota^{-1}(P))x_i
\\\overset{\text{evaluate at }\iota^{-1}(P)}=& \sum_{i=0}^n \left(\sum_{j=0}^n (\del_{x_j}f)(P) \cdot \del_{x_i}(\iota_j)\right)x_i
\\\overset{\text{interchange summation}}=& \sum_{j=0}^n (\del_{x_j}f)(P) \sum_{i=0}^n \del_{x_i}(\iota_j))x_i
\\\overset{\text{Euler's formula}}=& \sum_{j=0}^n (\del_{x_j}f)(P) \iota_j
\\\defeq& f^{(1)}(P).\iota
\end{align}
\end{proof}

\begin{corollary}
Let $\phi : \proj^n_k \to \proj^n_k$ be a projective transformation and $S = \V(f)$ a hypersurface.
Then a point $P \in S$ is singular iff $\phi(P) \in \phi(S)$ is.
\end{corollary}
\begin{proof}
The hypersurface $S$ is singular at $P$ iff $T_P(S) = \proj^n_k$ iff $T_{\phi(P)}(\phi(S)) = \phi(T_P(S)) = \proj^n_k$ iff $\phi(S)$ is singular at $\phi(P)$.
\end{proof}

With this observation at hand, we can easily make sense of the following lemma:

\begin{lemma} \label{lemmaIntersectionWithTangent}
Let $S = \V(I) \subset \proj^N_k$ be a projective variety, $P\in S$.
Clearly, as intersection of hyperplanes the tangent space at $P$ is a linear subspace of $\proj^N_k$ and hence the image of some linear embedding $\iota : \proj^n_k \hookr \proj^N_k$.
$\iota^{-1}(S)$ has a singularity at $\iota^{-1}(P)$.
\end{lemma}
\begin{proof}
By corollary \ref{corollaryTangentPullback} the tangent space of $\iota^{-1}(S)$ at $\iota^{-1}(P)$ is $\iota^{-1}(T_P(S)) = \iota^{-1}(\var{im}(\iota)) = \proj^n_k$, thus $\iota^{-1}(P)$ is a singular point.
\end{proof}
